import streamlit as st
import pandas as pd
import json
import os
import requests
import re
import unicodedata
import base64
from datetime import datetime

# --- è¨­å®š ---
DATA_FILE = 'manga_data.json'

# --- Secretsèª­ã¿è¾¼ã¿ ---
# GitHub
GITHUB_TOKEN = st.secrets.get("github", {}).get("token")
REPO_NAME = st.secrets.get("github", {}).get("repo") 
BRANCH = st.secrets.get("github", {}).get("branch", "main")

# æ¥½å¤© (å…¥ã‚Œå­ã«ãªã£ã¦ã„ãªã„å ´åˆã‚„ã€ã‚­ãƒ¼åã®é–“é•ã„ã«å¯¾å¿œã™ã‚‹ãŸã‚å®‰å…¨ã«å–å¾—)
# [rakuten] app_id = "..." ã®å½¢å¼ã‚’æƒ³å®š
RAKUTEN_APP_ID_SECRET = ""
if "rakuten" in st.secrets:
    RAKUTEN_APP_ID_SECRET = st.secrets["rakuten"].get("app_id", "")
elif "RAKUTEN_APP_ID" in st.secrets:
    RAKUTEN_APP_ID_SECRET = st.secrets["RAKUTEN_APP_ID"]

# --- é–¢æ•°å®šç¾© ---

def load_data():
    """ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    data = []
    # 1. GitHubã‹ã‚‰ãƒ­ãƒ¼ãƒ‰
    if GITHUB_TOKEN and REPO_NAME:
        url = f"https://api.github.com/repos/{REPO_NAME}/contents/{DATA_FILE}?ref={BRANCH}"
        headers = {"Authorization": f"token {GITHUB_TOKEN}", "Accept": "application/vnd.github.v3+json"}
        try:
            response = requests.get(url, headers=headers)
            if response.status_code == 200:
                content = base64.b64decode(response.json()['content']).decode('utf-8')
                data = json.loads(content)
            elif response.status_code == 404:
                data = []
        except Exception:
            pass 
    
    # 2. ãƒ­ãƒ¼ã‚«ãƒ«ã‹ã‚‰ãƒ­ãƒ¼ãƒ‰
    if not data and os.path.exists(DATA_FILE):
        try:
            with open(DATA_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except json.JSONDecodeError:
            data = []
    
    # ãƒ‡ãƒ¼ã‚¿è£œå®Œï¼ˆis_unreadã¯å‰Šé™¤ï¼‰
    for d in data:
        d.setdefault('my_score', 0)
        d.setdefault('genre', 'æœªåˆ†é¡')
        d.setdefault('is_finished', False)
        d.setdefault('title', 'No Title')
        d.setdefault('status', 'own') # åŸºæœ¬çš„ã«æ‰€æŒã®ã¿
    return data

def save_data(data):
    """ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã™ã‚‹"""
    json_str = json.dumps(data, indent=4, ensure_ascii=False)
    
    with open(DATA_FILE, 'w', encoding='utf-8') as f:
        f.write(json_str)

    if GITHUB_TOKEN and REPO_NAME:
        url = f"https://api.github.com/repos/{REPO_NAME}/contents/{DATA_FILE}"
        headers = {"Authorization": f"token {GITHUB_TOKEN}", "Accept": "application/vnd.github.v3+json"}
        
        sha = None
        try:
            get_resp = requests.get(url + f"?ref={BRANCH}", headers=headers)
            if get_resp.status_code == 200:
                sha = get_resp.json()['sha']
        except:
            pass

        content_b64 = base64.b64encode(json_str.encode('utf-8')).decode('utf-8')
        payload = {
            "message": f"Update data {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "content": content_b64,
            "branch": BRANCH
        }
        if sha:
            payload["sha"] = sha
            
        try:
            requests.put(url, headers=headers, json=payload)
        except Exception as e:
            st.error(f"GitHubä¿å­˜ä¾‹å¤–: {e}")

def normalize_title(title):
    """ã‚·ãƒªãƒ¼ã‚ºåæŠ½å‡ºï¼ˆå¼·åŠ›ç‰ˆï¼‰"""
    if not title: return ""
    title = unicodedata.normalize('NFKC', title)
    patterns = [
        r'\s*\(\d+\)', r'\s*\[\d+\]', r'\s*<\d+>', 
        r'\s*ç¬¬\d+å·»', r'\s*ç¬¬\d+é›†', r'\s*\d+å·»',
        r'\s*Vol\.?\s*\d+', r'\s*Volume\.?\s*\d+', r'\s*#\d+',
    ]
    for pattern in patterns:
        title = re.sub(pattern, ' ', title, flags=re.IGNORECASE)
    title = re.sub(r'\s+\d+(\s|$)', ' ', title)
    return re.sub(r'\s+', ' ', title).strip()

def extract_volume(title):
    """å·»æ•°æŠ½å‡º"""
    if not title: return 1
    title_norm = unicodedata.normalize('NFKC', title)
    patterns = [
        r'ç¬¬(\d+)å·»', r'\d+å·»', r'Vol\.?(\d+)', 
        r'[\(\[\<](\d+)[\)\]\>]', r'\s(\d+)\s', r'(\d+)$',
    ]
    for pattern in patterns:
        match = re.search(pattern, title_norm, re.IGNORECASE)
        if match: return int(match.group(1))
    return 1

# --- æ¥½å¤©ãƒ–ãƒƒã‚¯ã‚¹API ---

def search_rakuten_books(query, app_id, genre_id="001001", hits=30, sort="+releaseDate"):
    if not query or not app_id: return []
    
    url = "https://app.rakuten.co.jp/services/api/BooksTotal/Search/20170404"
    params = {"applicationId": app_id, "keyword": query, "hits": hits, "sort": sort}
    if genre_id: params["booksGenreId"] = genre_id

    results = []
    try:
        response = requests.get(url, params=params)
        data = response.json()
        if "Items" in data:
            for item in data["Items"]:
                info = item.get("Item", {})
                title = info.get("title", "")
                isbn = info.get("isbn", "")
                
                # é‡è¤‡é™¤å¤–ãªã—ã§æ¤œç´¢çµæœã‚’è¿”ã™ï¼ˆæœ€æ–°åˆŠåˆ¤å®šã®ãŸã‚ï¼‰
                if title:
                    results.append({
                        "title": title, "author": info.get("author", "ä¸æ˜"),
                        "publisher": info.get("publisherName", ""), "image": info.get("largeImageUrl", ""),
                        "link": info.get("itemUrl", ""), "isbn": isbn, "releaseDate": info.get("salesDate", ""),
                        "source": "Rakuten"
                    })
        return results
    except: return []

def get_series_stats(series_title, app_id):
    """ã‚·ãƒªãƒ¼ã‚ºã®æœ€æ–°åˆŠï¼ˆæœ€å¤§å·»æ•°ï¼‰ã¨ä»£è¡¨æƒ…å ±ã‚’å–å¾—"""
    if not app_id or not series_title: return 1, None
    
    # æ–°ã—ã„é †ã«æ¤œç´¢ã—ã¦æœ€å¤§å·»æ•°ã‚’æ¢ã™
    results = search_rakuten_books(series_title, app_id, hits=20, sort="-releaseDate")
    max_vol = 1
    meta = None
    
    if results:
        meta = results[0] # æœ€æ–°ã®ã‚‚ã®ã‚’ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å€™è£œã«ã™ã‚‹
        for res in results:
            v = extract_volume(res['title'])
            if v > max_vol:
                max_vol = v
                
        # 1å·»ã®ç”»åƒãŒæ¬²ã—ã„ã®ã§å¤ã„é †ã§ã‚‚æ¤œç´¢ã—ã¦ã¿ã‚‹
        old_results = search_rakuten_books(series_title, app_id, hits=1, sort="+releaseDate")
        if old_results:
            meta = old_results[0] # 1å·»ã®æƒ…å ±ã‚’å„ªå…ˆ

    return max_vol, meta

def get_next_volume_info(series_title, next_vol, app_id):
    """æ¬¡å·»æƒ…å ±å–å¾—"""
    if not app_id: return None
    query = f"{series_title} {next_vol}"
    results = search_rakuten_books(query, app_id, hits=10, sort="+releaseDate")
    if not results: return None
    exclude = ["ç‰¹è£…ç‰ˆ", "é™å®šç‰ˆ", "åŒæ¢±ç‰ˆ"]
    for res in results:
        if not any(kw in res["title"] for kw in exclude): return res
    return results[0]


# --- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æœ¬ä½“ ---

st.set_page_config(page_title="æ¼«ç”»ç®¡ç†ã‚¢ãƒ—ãƒª", layout="wide")

if 'manga_data' not in st.session_state:
    st.session_state.manga_data = load_data()
if 'search_results' not in st.session_state:
    st.session_state.search_results = []
if 'selected_book' not in st.session_state:
    st.session_state.selected_book = None
if 'last_search_query' not in st.session_state:
    st.session_state.last_search_query = ""
# ã‚·ãƒªãƒ¼ã‚ºæƒ…å ±ä¿æŒç”¨
if 'series_max_vol' not in st.session_state:
    st.session_state.series_max_vol = 1
if 'series_meta_info' not in st.session_state:
    st.session_state.series_meta_info = {}

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.title("ğŸ“š ãƒ¡ãƒ‹ãƒ¥ãƒ¼")
    view_mode = st.radio("è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰", ["â• æ¼«ç”»ç™»éŒ²", "ğŸ† å…¨ä»¶ãƒªã‚¹ãƒˆ", "ğŸ¨ ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥"])
    st.divider()
    
    st.header("âš™ï¸ è¨­å®š")
    # Secretsã‹ã‚‰å–å¾—ã—ãŸå€¤ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã«è¨­å®š
    rakuten_app_id = st.text_input("æ¥½å¤© Application ID", value=RAKUTEN_APP_ID_SECRET, type="password")
    
    if GITHUB_TOKEN and REPO_NAME:
        st.success(f"â˜ï¸ GitHubé€£æºä¸­")
    else:
        st.info("â˜ï¸ GitHubæœªè¨­å®š")

# --- å…±é€šé–¢æ•° ---
def update_data(edited_df):
    updated_list = edited_df.to_dict(orient="records")
    current_data_map = {d['id']: d for d in st.session_state.manga_data}
    for item in updated_list:
        if item['id'] in current_data_map:
            current_data_map[item['id']] = item
    st.session_state.manga_data = list(current_data_map.values())
    save_data(st.session_state.manga_data)

@st.dialog("è©³ç´°ç·¨é›†")
def edit_dialog(item):
    with st.form(f"edit_form_{item['id']}"):
        col1, col2 = st.columns([1, 2])
        with col1:
            if item.get("image"): st.image(item["image"], width=100)
            else: st.write("No Image")
        with col2:
            new_title = st.text_input("ã‚¿ã‚¤ãƒˆãƒ«", item["title"])
            new_vol = st.number_input("å·»æ•°", value=item["volume"], step=1)
            new_score = st.slider("è©•ä¾¡", 0, 5, item["my_score"])
            new_date = st.text_input("ç™ºå£²æ—¥", item["releaseDate"])
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç·¨é›†ã¯æ®‹ã™ãŒã€åŸºæœ¬own
            
            if st.form_submit_button("æ›´æ–°"):
                for d in st.session_state.manga_data:
                    if d['id'] == item['id']:
                        d['title'] = new_title; d['volume'] = new_vol
                        d['my_score'] = new_score; d['releaseDate'] = new_date
                        break
                save_data(st.session_state.manga_data)
                st.rerun()
            
            if st.form_submit_button("å‰Šé™¤", type="primary"):
                st.session_state.manga_data = [d for d in st.session_state.manga_data if d['id'] != item['id']]
                save_data(st.session_state.manga_data)
                st.rerun()

# --- ãƒ¡ã‚¤ãƒ³ãƒ“ãƒ¥ãƒ¼ ---
if view_mode == "â• æ¼«ç”»ç™»éŒ²":
    st.header("æ¼«ç”»ç™»éŒ² (æ‰€æŒã‚³ãƒŸãƒƒã‚¯)")
    if not rakuten_app_id: st.warning("âš ï¸ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§æ¥½å¤©Application IDã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")

    # 1. æ¤œç´¢ã‚¨ãƒªã‚¢
    with st.container():
        search_query = st.text_input("ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢ (å…¥åŠ›ã—ã¦Enter)", placeholder="ä¾‹: å‘ªè¡“å»»æˆ¦", key="s_in")
        
        # è‡ªå‹•æ¤œç´¢
        if search_query and rakuten_app_id and search_query != st.session_state.last_search_query:
            with st.spinner('ã‚·ãƒªãƒ¼ã‚ºæƒ…å ±ã‚’æ¤œç´¢ä¸­...'):
                st.session_state.selected_book = None
                results = search_rakuten_books(search_query, rakuten_app_id, genre_id="001001", hits=20)
                st.session_state.search_results = results
                st.session_state.last_search_query = search_query 
                st.session_state.series_max_vol = 1
                if not results: st.warning("è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        # å€™è£œé¸æŠ
        if st.session_state.search_results:
            opts = ["(é¸æŠã—ã¦ãã ã•ã„)"] + [f"{r['title']}" for r in st.session_state.search_results]
            sel = st.selectbox("â†“ ã‚·ãƒªãƒ¼ã‚ºã‚’é¸æŠã—ã¦ãã ã•ã„", opts, key="s_sel")
            
            if sel != "(é¸æŠã—ã¦ãã ã•ã„)":
                current_sel = st.session_state.search_results[opts.index(sel)-1]
                
                # é¸æŠãŒå¤‰ã‚ã£ãŸæ™‚ã ã‘è©³ç´°æ¤œç´¢ï¼ˆAPIç¯€ç´„ï¼‰
                if st.session_state.selected_book != current_sel:
                    st.session_state.selected_book = current_sel
                    # ã‚·ãƒªãƒ¼ã‚ºåæ­£è¦åŒ–ã—ã¦æœ€æ–°åˆŠã‚’æ¢ã™
                    norm_title = normalize_title(current_sel['title'])
                    with st.spinner(f'ã€Œ{norm_title}ã€ã®æ—¢åˆŠæƒ…å ±ã‚’ç¢ºèªä¸­...'):
                        max_vol, meta_info = get_series_stats(norm_title, rakuten_app_id)
                        st.session_state.series_max_vol = max_vol
                        # ãƒ¡ã‚¿æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Œã°æ›´æ–°ã€ãªã‘ã‚Œã°æ¤œç´¢çµæœã®ã‚‚ã®ã‚’ä½¿ã†
                        if meta_info:
                            st.session_state.series_meta_info = meta_info
                        else:
                            st.session_state.series_meta_info = current_sel

    # 2. ä¸€æ‹¬ç™»éŒ²ï¼ˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ï¼‰ã‚¨ãƒªã‚¢
    if st.session_state.selected_book:
        # ãƒ¡ã‚¿æƒ…å ±ã®æº–å‚™
        meta = st.session_state.series_meta_info
        series_title = normalize_title(meta['title']) if meta else ""
        max_v = st.session_state.series_max_vol
        
        st.divider()
        st.subheader(f"ğŸ“– {series_title}")
        st.caption(f"æœ€æ–°åˆŠã¯ **{max_v}å·»** ã‚ãŸã‚Šã§ã™")

        with st.form("bulk_reg"):
            st.write("æ‰€æŒã—ã¦ã„ã‚‹å·»æ•°ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
            
            # ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ (æœ€å¤§å€¤ãŒ1ã®å ´åˆã¯2ã«ã™ã‚‹)
            slider_limit = max(max_v, 2)
            owned_vol = st.slider("ä½•å·»ã¾ã§æŒã£ã¦ã„ã¾ã™ã‹ï¼Ÿ", 1, slider_limit, 1)
            
            st.info(f"ğŸ‘‰ **1å·» ã€œ {owned_vol}å·»** ã‚’ã€Œæ‰€æŒã€ã¨ã—ã¦ç™»éŒ²ã—ã¾ã™")
            
            genre = st.text_input("ã‚¸ãƒ£ãƒ³ãƒ«", placeholder="å°‘å¹´, ã‚¢ã‚¯ã‚·ãƒ§ãƒ³", value="å°‘å¹´")

            if st.form_submit_button("ä¸€æ‹¬ç™»éŒ²ã™ã‚‹", type="primary"):
                added_count = 0
                for v in range(1, owned_vol + 1):
                    # æ—¢ã«ç™»éŒ²æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯
                    exists = False
                    for existing in st.session_state.manga_data:
                        if existing['title'] == series_title and existing['volume'] == v:
                            exists = True
                            break
                    
                    if not exists:
                        new_d = {
                            "id": datetime.now().strftime("%Y%m%d%H%M%S") + str(v),
                            "title": series_title,
                            "volume": v,
                            "status": "own",   # å¼·åˆ¶çš„ã«æ‰€æŒ
                            "my_score": 0,
                            "genre": genre,
                            "is_finished": False,
                            "image": meta.get("image", ""),
                            "author": meta.get("author", ""),
                            "publisher": meta.get("publisher", ""),
                            "isbn": "", 
                            "link": meta.get("link", ""),
                            "releaseDate": ""
                        }
                        st.session_state.manga_data.append(new_d)
                        added_count += 1
                
                save_data(st.session_state.manga_data)
                
                if added_count > 0:
                    st.success(f"ã€{series_title}ã€ã‚’1ã€œ{owned_vol}å·»ã¾ã§ç™»éŒ²ã—ã¾ã—ãŸï¼ï¼ˆè¨ˆ{added_count}å†Šï¼‰")
                    st.session_state.search_results = []
                    st.session_state.selected_book = None
                    st.session_state.last_search_query = ""
                    st.rerun()
                else:
                    st.warning("æŒ‡å®šã•ã‚ŒãŸå·»ã¯ã™ã¹ã¦ç™»éŒ²æ¸ˆã¿ã§ã™ã€‚")

    st.divider()
    st.subheader("ğŸ“š æœ¬æ£š")

    if st.session_state.manga_data:
        df = pd.DataFrame(st.session_state.manga_data)
        df['series_key'] = df['title'].apply(normalize_title)
        
        series_groups = []
        for key, group in df.groupby('series_key'):
            min_vol_row = group.loc[group['volume'].idxmin()]
            latest_row = group.loc[group['volume'].idxmax()]
            
            series_groups.append({
                "title": key if key else "No Title",
                "df": group.sort_values("volume"),
                "image": min_vol_row.get('image', ''),
                "link": min_vol_row.get('link', ''),
                "last_updated": group['id'].max(),
                "max_vol": group['volume'].max(),
                "meta": latest_row.to_dict()
            })
        
        series_groups.sort(key=lambda x: x['last_updated'], reverse=True)
        cols = st.columns(4)

        for i, series in enumerate(series_groups):
            col = cols[i % 4]
            with col:
                if series['image']:
                    link_target = series['link'] if series['link'] else "#"
                    st.markdown(f"[![{series['title']}]({series['image']})]({link_target})", unsafe_allow_html=True)
                else:
                    st.markdown(f"<div style='background:#eee;height:150px;text-align:center;padding:60px 0;'>No Img</div>", unsafe_allow_html=True)
                
                with st.expander(f"ğŸ“‚ {series['title']} ({len(series['df'])})"):
                    # æ¬¡å·»è¿½åŠ ãƒœã‚¿ãƒ³
                    next_vol_num = int(series['max_vol']) + 1
                    if st.button(f"â• Vol.{next_vol_num} è¿½åŠ ", key=f"add_n_{series['title']}"):
                        with st.spinner("æ¤œç´¢ä¸­..."):
                            new_info = get_next_volume_info(series['title'], next_vol_num, rakuten_app_id)
                            base = series['meta']
                            new_entry = {
                                "id": datetime.now().strftime("%Y%m%d%H%M%S"),
                                "title": series['title'], "volume": next_vol_num, "status": "own",
                                "my_score": 0, "genre": base.get("genre", ""), "is_finished": False,
                                "author": base.get("author", ""), "publisher": base.get("publisher", ""),
                                "image": new_info.get("image", "") if new_info else "",
                                "link": new_info.get("link", "") if new_info else "",
                                "isbn": new_info.get("isbn", "") if new_info else "",
                                "releaseDate": new_info.get("releaseDate", "") if new_info else ""
                            }
                            st.session_state.manga_data.append(new_entry)
                            save_data(st.session_state.manga_data)
                            st.toast(f"Vol.{next_vol_num} è¿½åŠ ï¼")
                            st.rerun()
                    st.divider()
                    
                    vol_cols = st.columns(4)
                    for j, (idx, row) in enumerate(series['df'].iterrows()):
                        with vol_cols[j % 4]:
                            if row.get("image"): st.image(row["image"], use_container_width=True)
                            else: st.caption("No Image")
                            if st.button("ç·¨é›†", key=f"ve_{row['id']}"):
                                edit_dialog(row.to_dict())
    else:
        st.info("ã¾ã æ¼«ç”»ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

# --- ä»–ã®ãƒ“ãƒ¥ãƒ¼ ---
common_column_config = {
    "image": st.column_config.ImageColumn("è¡¨ç´™", width="small"),
    "title": "ã‚¿ã‚¤ãƒˆãƒ«", "volume": st.column_config.NumberColumn("å·»", format="%d"),
    "releaseDate": st.column_config.TextColumn("ç™ºå£²æ—¥"),
    "status": st.column_config.SelectboxColumn("çŠ¶æ…‹", options=["own", "want"]),
    "my_score": st.column_config.NumberColumn("è©•ä¾¡", format="%dâ­"),
    "is_finished": st.column_config.CheckboxColumn("å®Œ"),
    "link": st.column_config.LinkColumn("Link"),
    "id": None, "author": None, "publisher": None, "isbn": None, "genre": None
}

if view_mode == "ğŸ† å…¨ä»¶ãƒªã‚¹ãƒˆ":
    st.header("ğŸ† å…¨ä»¶ãƒªã‚¹ãƒˆ")
    if st.session_state.manga_data:
        df = pd.DataFrame(st.session_state.manga_data).sort_values(["my_score", "title"], ascending=[False, True])
        e_df = st.data_editor(df, column_config=common_column_config, use_container_width=True, hide_index=True, key="e_all")
        if not df.equals(e_df): update_data(e_df); st.rerun()

if view_mode == "ğŸ¨ ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥":
    st.header("ğŸ¨ ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥")
    if st.session_state.manga_data:
        df = pd.DataFrame(st.session_state.manga_data)
        genres = set()
        for g in df['genre'].unique():
            if g:
                for sub in g.replace('ã€',',').split(','): genres.add(sub.strip())
        if "" in genres: genres.remove("")
        g_list = sorted(list(genres)) + ["æœªåˆ†é¡"]
        for g in g_list:
            mask = (df['genre']=="")|(df['genre']=="æœªåˆ†é¡") if g=="æœªåˆ†é¡" else df['genre'].str.contains(g, na=False)
            df_g = df[mask].sort_values("my_score", ascending=False)
            if not df_g.empty:
                with st.expander(f"{g} ({len(df_g)})", expanded=True):
                    st.dataframe(df_g, column_config=common_column_config, use_container_width=True, hide_index=True)

st.divider()
if st.session_state.manga_data:
    df = pd.DataFrame(st.session_state.manga_data)
    st.download_button("CSVä¿å­˜", df.to_csv(index=False).encode('utf-8-sig'), "manga.csv", "text/csv")
